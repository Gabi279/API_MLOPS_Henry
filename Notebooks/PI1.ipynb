{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (17.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyarrow) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2024.5.0-cp310-cp310-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (1.24.3)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.8.3-cp310-none-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting fsspec (from fastparquet)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fastparquet) (24.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cgabr\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Downloading fastparquet-2024.5.0-cp310-cp310-win_amd64.whl (672 kB)\n",
      "   ---------------------------------------- 0.0/672.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 672.1/672.1 kB 5.3 MB/s eta 0:00:00\n",
      "Downloading cramjam-2.8.3-cp310-none-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 14.6 MB/s eta 0:00:00\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Installing collected packages: fsspec, cramjam, fastparquet\n",
      "Successfully installed cramjam-2.8.3 fastparquet-2024.5.0 fsspec-2024.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cgabr\\AppData\\Local\\Temp\\ipykernel_2584\\687473288.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_movies = pd.read_csv(\"C:/Users/cgabr/OneDrive/Documentos/Henry/Movies/API/Data/movies_dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Carga de datos de las películas y de los créditos\n",
    "\n",
    "data_movies = pd.read_csv(\"C:/Users/cgabr/OneDrive/Documentos/Henry/Movies/API/Data/movies_dataset.csv\")\n",
    "data_credits = pd.read_csv(\"C:/Users/cgabr/OneDrive/Documentos/Henry/Movies/API\\Data/credits.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>production_companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'name': 'Pixar Animation Studios', 'id': 3}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'name': 'TriStar Pictures', 'id': 559}, {'na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'name': 'Warner Bros.', 'id': 6194}, {'name'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'name': 'Twentieth Century Fox Film Corporat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'name': 'Sandollar Productions', 'id': 5842}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45461</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45462</th>\n",
       "      <td>[{'name': 'Sine Olivia', 'id': 19653}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45463</th>\n",
       "      <td>[{'name': 'American World Pictures', 'id': 6165}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45464</th>\n",
       "      <td>[{'name': 'Yermoliev', 'id': 88753}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45465</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45466 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    production_companies\n",
       "0         [{'name': 'Pixar Animation Studios', 'id': 3}]\n",
       "1      [{'name': 'TriStar Pictures', 'id': 559}, {'na...\n",
       "2      [{'name': 'Warner Bros.', 'id': 6194}, {'name'...\n",
       "3      [{'name': 'Twentieth Century Fox Film Corporat...\n",
       "4      [{'name': 'Sandollar Productions', 'id': 5842}...\n",
       "...                                                  ...\n",
       "45461                                                 []\n",
       "45462             [{'name': 'Sine Olivia', 'id': 19653}]\n",
       "45463  [{'name': 'American World Pictures', 'id': 6165}]\n",
       "45464               [{'name': 'Yermoliev', 'id': 88753}]\n",
       "45465                                                 []\n",
       "\n",
       "[45466 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformación a dataframes de las columnas belongs_to_collection y production_companies para desanidarlas\n",
    "\n",
    "df_btc = pd.DataFrame(data=data_movies['belongs_to_collection'])\n",
    "df_btc\n",
    "\n",
    "df_prod = pd.DataFrame(data=data_movies['production_companies'])\n",
    "df_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'cast_id': 14, 'character': 'Woody (voice)',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'Alan Parrish', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{'cast_id': 2, 'character': 'Max Goldman', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{'cast_id': 1, 'character': \"Savannah 'Vannah...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{'cast_id': 1, 'character': 'George Banks', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45471</th>\n",
       "      <td>[{'cast_id': 0, 'character': '', 'credit_id': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45472</th>\n",
       "      <td>[{'cast_id': 1002, 'character': 'Sister Angela...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45473</th>\n",
       "      <td>[{'cast_id': 6, 'character': 'Emily Shaw', 'cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45474</th>\n",
       "      <td>[{'cast_id': 2, 'character': '', 'credit_id': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45475</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45476 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    cast\n",
       "0      [{'cast_id': 14, 'character': 'Woody (voice)',...\n",
       "1      [{'cast_id': 1, 'character': 'Alan Parrish', '...\n",
       "2      [{'cast_id': 2, 'character': 'Max Goldman', 'c...\n",
       "3      [{'cast_id': 1, 'character': \"Savannah 'Vannah...\n",
       "4      [{'cast_id': 1, 'character': 'George Banks', '...\n",
       "...                                                  ...\n",
       "45471  [{'cast_id': 0, 'character': '', 'credit_id': ...\n",
       "45472  [{'cast_id': 1002, 'character': 'Sister Angela...\n",
       "45473  [{'cast_id': 6, 'character': 'Emily Shaw', 'cr...\n",
       "45474  [{'cast_id': 2, 'character': '', 'credit_id': ...\n",
       "45475                                                 []\n",
       "\n",
       "[45476 rows x 1 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformación a dataframe de la columna cast para desanidarlas\n",
    "\n",
    "df_cast = pd.DataFrame(data=data_credits['cast'])\n",
    "df_cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_btc = df_btc.drop_duplicates()\n",
    "df_btc = df_btc.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prod = df_prod.drop_duplicates()\n",
    "df_prod = df_prod.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cast = df_cast.drop_duplicates()\n",
    "df_cast = df_cast.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        [Tom Hanks, Tim Allen, Don Rickles, Jim Varney...\n",
      "1        [Robin Williams, Jonathan Hyde, Kirsten Dunst,...\n",
      "2        [Walter Matthau, Jack Lemmon, Ann-Margret, Sop...\n",
      "3        [Whitney Houston, Angela Bassett, Loretta Devi...\n",
      "4        [Steve Martin, Diane Keaton, Martin Short, Kim...\n",
      "                               ...                        \n",
      "45471          [Leila Hatami, Kourosh Tahami, Elham Korda]\n",
      "45472    [Angel Aquino, Perry Dizon, Hazel Orencio, Joe...\n",
      "45473    [Erika Eleniak, Adam Baldwin, Julie du Page, J...\n",
      "45474    [Iwan Mosschuchin, Nathalie Lissenko, Pavel Pa...\n",
      "45475                                                   []\n",
      "Name: actors, Length: 45476, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conviersión de la columna \"cast\" a listas de diccionarios\n",
    "data_credits['cast'] = data_credits['cast'].apply(ast.literal_eval)\n",
    "\n",
    "# Aplica la función lambda para extraer los nombres de los actores\n",
    "data_credits['actors'] = data_credits['cast'].apply(lambda x: [actor['name'] for actor in x])\n",
    "\n",
    "# Verificación del resultado\n",
    "print(data_credits['actors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte la columna \"crew\" en listas de diccionarios utilizando la función ast.literal_eval\n",
    "data_credits['crew'] = data_credits['crew'].apply(ast.literal_eval)\n",
    "\n",
    "# Utiliza una función lambda junto con una comprensión de lista para filtrar los elementos en los que el valor de la clave \"job\" sea igual a \"Director\" y extraer el valor de la clave \"name\" para esos elementos.\n",
    "data_credits['director_names'] = data_credits['crew'].apply(lambda x: [item['name'] for item in x if item['job'] == 'Director'])\n",
    "\n",
    "# Convierte la lista de nombres de directores en un solo string separado por comas.\n",
    "data_credits['director_names'] = data_credits['director_names'].apply(', '.join)\n",
    "data_credits.head()\n",
    "\n",
    "# Crea un nuevo dataframe con los datos de las columnas \n",
    "new_data_credits = data_credits.loc[:, ['id', 'actors', 'director_names']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se cambian los valores nulos por el valor 0\n",
    "\n",
    "revenue = data_movies['revenue'].fillna(0)\n",
    "budget = data_movies['budget'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan los valores nulos de la columna release_date\n",
    "\n",
    "data_movies.dropna(subset=['release_date'], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la columna release_year con los datos transformados a datetime\n",
    "\n",
    "data_movies['release_year'] = pd.to_datetime(data_movies['release_date'], format='%Y-%m-%d', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se convierten los datos a números para poder dividir las dos columnas\n",
    "\n",
    "data_movies['revenue'] = pd.to_numeric(data_movies['revenue'], errors='coerce')\n",
    "data_movies['budget'] = pd.to_numeric(data_movies['budget'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        12.451801\n",
       "1         4.043035\n",
       "2         0.000000\n",
       "3         5.090760\n",
       "4         0.000000\n",
       "           ...    \n",
       "45460     0.000000\n",
       "45462     0.000000\n",
       "45463     0.000000\n",
       "45464     0.000000\n",
       "45465     0.000000\n",
       "Name: return, Length: 45379, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se divide la columna revenue sobre budget para crear la columna return con el cociente de lasdos anteriores\n",
    "\n",
    "data_movies.loc[:, 'return'] = data_movies.apply(lambda row: row['revenue'] / row['budget'] if pd.notnull(row['revenue']) and pd.notnull(row['budget']) and row['budget'] != 0 else 0, axis=1)\n",
    "\n",
    "data_movies['return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se eliminan las columnas que no se van a utilizar en el futuro\n",
    "\n",
    "data_movies = data_movies.drop('video', axis=1)\n",
    "data_movies = data_movies.drop('imdb_id', axis=1)\n",
    "data_movies = data_movies.drop('adult', axis=1)\n",
    "data_movies = data_movies.drop('original_title', axis=1)\n",
    "data_movies = data_movies.drop('poster_path', axis=1)\n",
    "data_movies = data_movies.drop('homepage', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se corrige los valores de la columna popularity\n",
    "\n",
    "data_movies['popularity'] = pd.to_numeric(data_movies['popularity'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_credits = data_credits.drop('crew', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\cgabr\\OneDrive\\Documentos\\GitHub\\API_MLOPS_Henry\\venv\\lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyarrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Finalmente se transforman los datos a parquet para disminuir su peso\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdata_movies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata_movies.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m data_credits\u001b[38;5;241m.\u001b[39mto_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_credits.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m, engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cgabr\\OneDrive\\Documentos\\GitHub\\API_MLOPS_Henry\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cgabr\\OneDrive\\Documentos\\GitHub\\API_MLOPS_Henry\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3113\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[1;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   3032\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3033\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[0;32m   3034\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3109\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[0;32m   3110\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3111\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[1;32m-> 3113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_parquet(\n\u001b[0;32m   3114\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   3115\u001b[0m     path,\n\u001b[0;32m   3116\u001b[0m     engine,\n\u001b[0;32m   3117\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3118\u001b[0m     index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   3119\u001b[0m     partition_cols\u001b[38;5;241m=\u001b[39mpartition_cols,\n\u001b[0;32m   3120\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3122\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\cgabr\\OneDrive\\Documentos\\GitHub\\API_MLOPS_Henry\\venv\\lib\\site-packages\\pandas\\io\\parquet.py:476\u001b[0m, in \u001b[0;36mto_parquet\u001b[1;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(partition_cols, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    475\u001b[0m     partition_cols \u001b[38;5;241m=\u001b[39m [partition_cols]\n\u001b[1;32m--> 476\u001b[0m impl \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[0;32m    480\u001b[0m impl\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[0;32m    481\u001b[0m     df,\n\u001b[0;32m    482\u001b[0m     path_or_buf,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\cgabr\\OneDrive\\Documentos\\GitHub\\API_MLOPS_Henry\\venv\\lib\\site-packages\\pandas\\io\\parquet.py:78\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     75\u001b[0m     )\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPyArrowImpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FastParquetImpl()\n",
      "File \u001b[1;32mc:\\Users\\cgabr\\OneDrive\\Documentos\\GitHub\\API_MLOPS_Henry\\venv\\lib\\site-packages\\pandas\\io\\parquet.py:163\u001b[0m, in \u001b[0;36mPyArrowImpl.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow is required for parquet support.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cgabr\\OneDrive\\Documentos\\GitHub\\API_MLOPS_Henry\\venv\\lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "# Finalmente se transforman los datos a parquet para disminuir su peso\n",
    "\n",
    "data_movies.to_parquet('data_movies.parquet', engine='pyarrow')\n",
    "data_credits.to_parquet('data_credits.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n",
       "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
       "       'popularity', 'poster_path', 'production_companies',\n",
       "       'production_countries', 'release_date', 'revenue', 'runtime',\n",
       "       'spoken_languages', 'status', 'tagline', 'title', 'video',\n",
       "       'vote_average', 'vote_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_movies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies['id'] = data_movies['id'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies['id'] = pd.to_numeric(data_movies['id'], errors='coerce')\n",
    "data_movies['popularity'] = pd.to_numeric(data_movies['popularity'], errors='coerce')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
